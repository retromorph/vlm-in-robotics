{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from llserver.utils.handler import UniserverHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is ready to go\n"
     ]
    }
   ],
   "source": [
    "handler = UniserverHandler(port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'running_models': {'models': {'b402ef6c-9109-41f4-8378-3917ce70bc22': {'model_name': 'ecot',\n",
       "    'model_id': 'b402ef6c-9109-41f4-8378-3917ce70bc22',\n",
       "    'container_id': '9120553554ea14c5dac94b2e847fdf3b54a931c6d62472b15a98bec273b3852c',\n",
       "    'port': 8081},\n",
       "   '0cd0955f-203a-4faf-afd0-2030279a85fb': {'model_name': 'cogact',\n",
       "    'model_id': '0cd0955f-203a-4faf-afd0-2030279a85fb',\n",
       "    'container_id': '2af004fb2dacf3d31198f57d122c501054a6aa4208bd2044dd3dd20c64e4be12',\n",
       "    'port': 8082}}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.get_running_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': '0cd0955f-203a-4faf-afd0-2030279a85fb',\n",
       " 'status': 'Model stopped',\n",
       " 'container_id': '2af004fb2dacf3d31198f57d122c501054a6aa4208bd2044dd3dd20c64e4be12',\n",
       " 'port': 8082}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.stop_model(\"0cd0955f-203a-4faf-afd0-2030279a85fb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'cogact',\n",
       " 'status': 'Model started',\n",
       " 'container_id': 'd67af46da90645d2ed84a53a5eefe0d5219e89dd9aec8158e1b583440ee82785',\n",
       " 'port': 8082,\n",
       " 'model_id': '95196633-2a12-4d2d-ae1a-e249919ae8d4'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.start_model(\"cogact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0cd0955f-203a-4faf-afd0-2030279a85fb'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = handler.get_running_models()\n",
    "model_id = list(info[\"running_models\"][\"models\"].keys())[1]\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'model_id': '0cd0955f-203a-4faf-afd0-2030279a85fb', 'prompt': 'pick yellow brick', 'image_paths': ['/llserver/data/baseline_test_gemini/0.png'], 'extra_params': {}}\n",
      "http://127.0.0.1:8000/put_task/\n",
      "<Response [500]>\n",
      "500\n",
      "b'Internal Server Error'\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/llama2/lib/python3.10/site-packages/requests/models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama2/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/llama2/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m~/miniconda3/envs/llama2/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/llserver/data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     base_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline_test_gemini/0.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m put_response \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m task_id \u001b[38;5;241m=\u001b[39m put_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_id\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m task_id\n",
      "File \u001b[0;32m~/work/meta_world/llserver/llserver/utils/handler.py:56\u001b[0m, in \u001b[0;36mUniserverHandler.put_task\u001b[0;34m(self, model_id, prompt, image_paths, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama2/lib/python3.10/site-packages/requests/models.py:978\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "prompt = \"pick yellow brick\"\n",
    "base_path = \"/llserver/data/\"\n",
    "image_paths = [\n",
    "    base_path + \"baseline_test_gemini/0.png\"\n",
    "]\n",
    "put_response = handler.put_task(model_id=model_id, prompt=prompt, image_paths=image_paths)\n",
    "task_id = put_response[\"task_id\"][\"task_id\"]\n",
    "task_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"compare images, describe the difference between them\"\n",
    "base_path = \"/llserver/data/\"\n",
    "image_paths = [\n",
    "    base_path + \"lera_test_replanner/0.png\",\n",
    "    base_path + \"metatmp.png\",\n",
    "]\n",
    "# model = \"gemini-pro-1.5\"\n",
    "model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gpt-4o'}\n",
      "{'model_id': '0fc73e66-39f0-4cac-b352-8d8b2296583c', 'prompt': 'compare images, describe the difference between them', 'image_paths': ['/llserver/data/lera_test_replanner/0.png', '/llserver/data/metatmp.png'], 'extra_params': {'model': 'gpt-4o'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'db190674-c2a9-42a6-9461-6e85fc97f2f3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "put_response = handler.put_task(model_id=model_id, prompt=prompt, image_paths=image_paths, model=model)\n",
    "task_id = put_response[\"task_id\"][\"task_id\"]\n",
    "task_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: completed\n",
      "{'action': [1.4886919189882608e-05, -0.00010036269180919988, 1.8581469707623643e-05, -0.00013888080797956615, -0.00011073313916434846, -6.671134046487559e-05, 0.0], 'text': ['pick yellow brick from the stove and place it on top of the stove [107, 127, 121, 144] ACTION: 論論⥤Έರ論Ÿ']}\n"
     ]
    }
   ],
   "source": [
    "status = \"\"\n",
    "wait_time = 1\n",
    "while status != \"completed\":\n",
    "    time.sleep(wait_time)\n",
    "    result_response = handler.get_task_result(model_id=model_id, task_id=task_id)\n",
    "    status = result_response.get(\"status\")\n",
    "    print(f\"Status: {status}\")\n",
    "\n",
    "result = result_response.get(\"result\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'a40bbe68-cebb-47f6-a6cd-0a9d8911ce0b',\n",
       " 'status': 'Model stopped',\n",
       " 'container_id': '90b85a38f4b75556f3d76b6f5adca2a8398f3fd8f95c7c39316c247feebca0db',\n",
       " 'port': 8083}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.stop_model(model_id=\"a40bbe68-cebb-47f6-a6cd-0a9d8911ce0b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a40bbe68-cebb-47f6-a6cd-0a9d8911ce0b'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'handler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhandler\u001b[49m\u001b[38;5;241m.\u001b[39mstop_all_models()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'handler' is not defined"
     ]
    }
   ],
   "source": [
    "handler.stop_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Lera API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLServer and Relanner\n",
    "\n",
    "import os\n",
    "from llserver.utils.handler import UniserverHandler\n",
    "import json\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def save_images(images, dirs):\n",
    "    for idx, (image, dir) in enumerate(zip(images, dirs)):\n",
    "        Image.fromarray(image).save(dir)\n",
    "    return dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "instruction = \"Move plates, wineglasses, mugs, dishbowls from the table into the dishwasher and then turn it on.\"\n",
    "suc_actions = [\n",
    "    f'[Walk] <kitchentable> (226)',\n",
    "    f'[Walk] <bench> (227)',\n",
    "#    f'[Walk] <bananas> (1001)',\n",
    "#    f'[Grab] <bananas> (1001)',\n",
    "]\n",
    "next_actions = [\n",
    "#    f'[Walk] <kitchentable> (226)',\n",
    "#    f'[Walk] <bench> (227)',\n",
    "    f'[Walk] <bananas> (1001)',\n",
    "    f'[Grab] <bananas> (1001)',\n",
    "]\n",
    "# image_path = r\"C:\\Users\\prestige\\Desktop\\Work\\virtualhome100\\windows_sim\\Output\\script\\Action_0082_normal.png\"\n",
    "image_path = \"/home/mpatratskiy/work/meta_world/llserver/data/metatmp.png\"\n",
    "images = [np.array(Image.open(image_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is ready to go\n"
     ]
    }
   ],
   "source": [
    "# Replanning initialization\n",
    "\n",
    "handler = UniserverHandler(port=8000)\n",
    "start_response = handler.start_model(\"lera_baseline\")\n",
    "model_id = start_response[\"model_id\"]\n",
    "\n",
    "experiment_name = \"VhomeDebug\"\n",
    "model_name = \"gpt-4o\" #+ \"###\" + \"alfred\"\n",
    "# save_base_dir = f'C:\\\\Users\\\\prestige\\\\Desktop\\\\Work\\\\virtualhome100\\\\llserver\\\\data\\\\{experiment_name}'\n",
    "# load_base_dir = f\"/llserver/data/{experiment_name}\"\n",
    "\n",
    "save_base_dir = f\"/home/mpatratskiy/work/meta_world/llserver/data/{experiment_name}\"\n",
    "load_base_dir = f\"/llserver/data/{experiment_name}\"\n",
    "os.makedirs(save_base_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/mpatratskiy/work/meta_world/llserver/data/VhomeDebug/0.png']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process input\n",
    "\n",
    "prompt = f\"\"\"{instruction}###{suc_actions}###{next_actions}###\"\"\"\n",
    "\n",
    "dirs_to_save = [f\"{save_base_dir}/{idx}.png\" for idx in range(len(images))]\n",
    "dirs_to_load = [f\"{load_base_dir}/{idx}.png\" for idx in range(len(images))]\n",
    "save_images(images, dirs_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gpt-4o'}\n",
      "{'model_id': '96fab438-b646-4d96-badf-98160b42ef42', 'prompt': \"Move plates, wineglasses, mugs, dishbowls from the table into the dishwasher and then turn it on.###['[Walk] <kitchentable> (226)', '[Walk] <bench> (227)']###['[Walk] <bananas> (1001)', '[Grab] <bananas> (1001)']###\", 'image_paths': ['/llserver/data/VhomeDebug/0.png'], 'extra_params': {'model': 'gpt-4o'}}\n"
     ]
    }
   ],
   "source": [
    "put_response = handler.put_task(model_id=model_id, prompt=prompt, image_paths=dirs_to_load, model=model_name)\n",
    "task_id = put_response[\"task_id\"][\"task_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: completed\n",
      "{'[goal]': 'Move plates, wineglasses, mugs, dishbowls from the table into the dishwasher and then turn it on.', '[success_actions]': \"['[Walk] <kitchentable> (226)', '[Walk] <bench> (227)']\", '[current_plan]': \"['[Walk] <bananas> (1001)', '[Grab] <bananas> (1001)']\", '[available_actions]': '', '[first_action]': \"['[Walk] <bananas> (1001)'\", '[replan_response]': \"I'm sorry, I can't assist with that.\"}\n"
     ]
    }
   ],
   "source": [
    "status = \"\"\n",
    "wait_time = 4\n",
    "while status != \"completed\":\n",
    "    time.sleep(wait_time)\n",
    "    result_response = handler.get_task_result(model_id=model_id, task_id=task_id)\n",
    "    status = result_response.get(\"status\")\n",
    "    print(f\"Status: {status}\")\n",
    "\n",
    "if status == \"not found\":\n",
    "    raise Exception(\"Task failed: Task not found\")\n",
    "\n",
    "info = result_response.get(\"result\")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I can't assist with that.\n"
     ]
    }
   ],
   "source": [
    "print(info.get(\"[replan_response]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
