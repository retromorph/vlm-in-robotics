{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=\"\",\n",
    "    base_url=\"https://api.aitunnel.ru/v1/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt, image_paths=[], model=\"gpt-4o\"):\n",
    "    content = [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": prompt\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    if len(image_paths) > 0:\n",
    "        for image_path in image_paths:\n",
    "            base64_image = encode_image(image_path)\n",
    "            content.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "            })\n",
    "    \n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content\n",
    "        }\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        max_tokens=500,\n",
    "        model=model\n",
    "    )\n",
    "\n",
    "    text_outputs = completion.choices[0].message.content\n",
    "    return text_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(text, model=\"gpt-4o\", **kwargs):\n",
    "    print(text)\n",
    "    print(model)\n",
    "    print(kwargs)\n",
    "\n",
    "foo(\"Hello\", model=\"kekw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path1 = \"~/work/meta_world/llserver/notebooks/metatmp1.png\"\n",
    "image_path2 = \"~/work/pybullet/Pybullet/saved_images/image.png\"\n",
    "\n",
    "prompt = \"Опиши эти изображения, что у них общего и чем они отличаются\"\n",
    "image_paths = [image_path1, image_path2]\n",
    "model = \"gemini-pro-1.5\"\n",
    "\n",
    "answer = predict(prompt, image_paths=image_paths, model=model)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"~/work/meta_world/llserver/notebooks/metatmp1.png\"\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What’s in this image?\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=500, # Старайтесь указывать для более точного расчёта цены\n",
    "    model=\"gemini-pro-1.5\"\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"path_to_your_image.jpg\"\n",
    "\n",
    "# Getting the base64 string\n",
    "\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4o\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What’s in this image?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "You are a helpful embodied assistant. You are helping with resolving errors in robot execution.\n",
    "During execution of last action you have encountered a problem. Robot failed executing last action.\n",
    "You are given a goal and a current plan and description of the current scene with ideas of what could be wrong.\n",
    "Provde ideas how to fix the problem. HINT: robot may accidently drop objects during gripper movement but continue to move fripper with object.\n",
    "Predict new plan what can fix the problem and reach the goal. Explain each choosen action briefly. You must use actions only from avaliable_actions in you predicted plan. Pay attention on action description. Do not use any other actions and formatting. Do not create combinations of actions.\n",
    "\n",
    "Action description:\n",
    "locate('object') - function that give you position of the object in the scene. Allows to move robot arm to the object in order to pick it up or place_on_top_of another object on it.\n",
    "pick('object') - function that pick up an object. Can be used only if object location is known. Thus you must use locate('object') before pick('object').\n",
    "place_on_top_of('object') - function that put something from gripper on top of the object, which name is provided to function. Example: place_on_top_of('blue block') - put anything from gripper on top of the blue block.\n",
    "done() - function that indicate that the task is completed.\n",
    "Each of locate, pick and place_on_top_of actions takes one argument - object name. You can not use any other arguments or multiple objects.\n",
    "\n",
    "Strong advice: \n",
    "- always use locate('object') before pick('object')\n",
    "- always use locate('object') before place_on_top_of('object')\n",
    "- pick('object') can be used only if gripper is empty and object is located\n",
    "- place_on_top_of('object') can be used only if gripper is NOT empty and object is located\n",
    "\n",
    "Scene description and ideas of what could be wrong:\n",
    "T\n",
    "\n",
    "Avaliable actions:\n",
    "[\"locate('red bowl')\", \"locate('red block')\", \"locate('green block')\", \"place_on_top_of('red bowl')\", \"place_on_top_of('blue block')\", \"place_on_top_of('green block')\", \"pick('blue block')\", \"locate('blue block')\", 'done()', \"pick('red bowl')\", \"pick('red block')\", \"pick('green block')\", \"place_on_top_of('red block')\"]\n",
    "\n",
    "Successfully executed actions:\n",
    "[\"locate('blue block')\", \"pick('blue block')\", \"locate('red bowl')\"]\n",
    "\n",
    "Current plan:\n",
    "[\"place_on_top_of('red bowl')\", \"locate('red block')\", \"pick('red block')\", \"locate('blue block')\", \"place_on_top_of('blue block')\", \"locate('green block')\", \"pick('green block')\", \"locate('red block')\", \"place_on_top_of('red block')\", 'done()']\n",
    "\n",
    "Current goal:\n",
    "stack all blocks on each other in the red bowl\n",
    "\"\"\".split()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
